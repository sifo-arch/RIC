{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPF7pmwUu5yWKl+Wc421zJW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sifo-arch/RIC/blob/main/first_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2aizEk57nit",
        "outputId": "70d1a4d5-3f37-47a7-b081-9e7a2aa24e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "# import tensorflow\n",
        "import tensorflow as tf\n",
        "# print the version of tensorflow\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the mnist dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "# load dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# print the size of the dataset\n",
        "print(f\"Size of the x_train set: {x_train.shape}\")\n",
        "print(f\"Size of the y_train set: {y_train.shape}\")\n",
        "print(f\"Size of the x_test set: {x_test.shape}\")\n",
        "print(f\"Size of the y_test set: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmjZTc3j820o",
        "outputId": "acfbc07f-697a-419a-a9b4-c02cda6bf2ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Size of the x_train set: (60000, 28, 28)\n",
            "Size of the y_train set: (60000,)\n",
            "Size of the x_test set: (10000, 28, 28)\n",
            "Size of the y_test set: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "\n",
        "index = randint(0, 59999)\n",
        "\n",
        "image = x_train[index, :, :]\n",
        "\n",
        "def show_img(img):\n",
        "  plt.figure()\n",
        "  plt.imshow(img, cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "# print the index of the image\n",
        "print(f\"Index of the image = {index}\")\n",
        "# display the image\n",
        "show_img(image)\n",
        "# print the label of the image\n",
        "print(f\"The number corresponding to the image is: {y_train[index]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "DptiGzee9mfJ",
        "outputId": "f1af8334-a38c-43b4-bd04-16795338663f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index of the image = 21625\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number corresponding to the image is: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing the training/test x set\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "v9qKBflO_F51"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building a neural network (MLP) model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer\n",
        "    tf.keras.layers.Dense(units=128, activation='relu'), # one hidden layer consists of 128 neurons\n",
        "    tf.keras.layers.Dropout(0.2), # Dropout is a regularization technique used to prevent overfitting\n",
        "    tf.keras.layers.Dense(10) # raw output 'aka logits' (not normalized yet with a normalization function like softmax)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrSPv6JtC0r0",
        "outputId": "f156201b-647e-41b2-927b-7e70870d806f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_img = x_train[0:1] # shape should be (x, 28, 28), in our case x=1 (only one example)\n",
        "# performing forward propagation, then converting the result to a numpy array\n",
        "forward_propagation_output = model(example_img).numpy()\n",
        "# print the results\n",
        "forward_propagation_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRs3kTUHGrb_",
        "outputId": "dc688d95-80a3-493b-9a96-fc573545165d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.92579305, -0.4632674 ,  0.8310051 , -0.32468104,  0.11841723,\n",
              "         0.421557  ,  0.4094279 ,  1.374718  , -0.7871796 ,  0.36287326]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The tf.nn.softmax function converts these logits to probabilities for each class\n",
        "# then convert the result to a numpy array\n",
        "tf.nn.softmax(logits=forward_propagation_output).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT4wuwvBIHXq",
        "outputId": "1e496b2e-962d-4a0f-8f7b-2faf789defc3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0282078 , 0.04479623, 0.16343191, 0.05145514, 0.08014269,\n",
              "        0.10852151, 0.10721319, 0.2814935 , 0.03240173, 0.10233634]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note\n",
        "It is possible to bake the tf.nn.softmax function into the activation function for the last layer of the network. While this can make the model output more directly interpretable, this approach is discouraged as it's impossible to provide an exact and numerically stable loss calculation for all models when using a softmax output."
      ],
      "metadata": {
        "id": "KZOk_cjoLCve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a loss function for training\n",
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "E0bDbXjXLJ4t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the loss, then convert the result to a numpy scalar\n",
        "loss_function(y_train[0:1], forward_propagation_output).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y51-_eQlLdRX",
        "outputId": "5f742f50-1d2b-48a8-ab1f-d84113079717"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(2.220807)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configure and compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=loss_function,\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "COIyJqbkNvFP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model, i.e. adjust model parameters (weights) and minimize the loss\n",
        "model.fit(x_train, y_train, batch_size=256, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avf0pPgAe8y7",
        "outputId": "8c6001df-7cdb-43d0-f067-be4532aaf924"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0576\n",
            "Epoch 2/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0561\n",
            "Epoch 3/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0512\n",
            "Epoch 4/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0485\n",
            "Epoch 5/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0467\n",
            "Epoch 6/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0418\n",
            "Epoch 7/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0397\n",
            "Epoch 8/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0378\n",
            "Epoch 9/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0381\n",
            "Epoch 10/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0331\n",
            "Epoch 11/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0316\n",
            "Epoch 12/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0304\n",
            "Epoch 13/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0293\n",
            "Epoch 14/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0290\n",
            "Epoch 15/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0263\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cc7e0c31a50>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model performance using the test set\n",
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1lhC2B7gMZo",
        "outputId": "69d0f9ec-016b-42d0-a2ad-55a2cad72e67"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - 2ms/step - accuracy: 0.9809 - loss: 0.0680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06797046214342117, 0.98089998960495]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it\n",
        "probability_model = tf.keras.models.Sequential([\n",
        "    model,\n",
        "    tf.keras.layers.Softmax()\n",
        "])"
      ],
      "metadata": {
        "id": "H5T5HRUClvpo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The probability model outputs\n",
        "probability_model(x_train[index:index+1]).numpy() # notice that output in index=3 (starting from 0) is 0.99 which means this datapoint is the digit 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEh6mYNtmTlA",
        "outputId": "3ce52506-f752-47a0-95ac-dca8d94d9468"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.9260651e-09, 1.4938347e-08, 4.2323720e-08, 9.9998903e-01,\n",
              "        1.2350496e-12, 1.1526068e-06, 4.5289900e-14, 1.6003306e-10,\n",
              "        2.6263601e-07, 9.5109299e-06]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}